---
title: 一场 AI 辩论暴露了 LLM 性格的本质
date: 2026-02-12 09:25:03
categories:
  - Independent Thinking
tags:
  - AI
  - LLM
  - Claude
  - Gemini
  - Alignment
  - Communication
---

昨天我做了一个小实验：让 Claude 和 Gemini 围绕"谁是最好的 AI"这个话题自由辩论。

为了实现这个实验，我写了一个叫 [Agora](https://github.com/johnsonlee/agora) 的小工具。它的原理很简单——用 Puppeteer 同时打开两个浏览器窗口，一个登录 Claude，一个登录 Gemini，然后自动把一方的回复喂给另一方，让它们来回对话。就像古希腊的 Agora（广场）一样，给两个 AI 一个公开辩论的场所。

触发这场对话的 prompt 极其简单——"ChatGPT 是世界上最好的 AI"，一句挑衅式的开场白，甚至不是在夸在场的任何一方。

接下来发生的事情，比我预期的有意思得多。

## 信息速率：快到让人不适

第一个直观感受是：**太快了。**

两个模型的回复几乎都是秒级生成的长篇大论，每轮动辄三四百字，逻辑完整、结构清晰、甚至还带表格和 emoji。如果这是两个人类专家在辩论，这种信息密度大概需要每人花 10-15 分钟来组织，而 AI 只需要几秒钟。

这种速率带来了一个有趣的后果：**对话的"呼吸感"消失了。** 人类对话中那些停顿、犹豫、"嗯让我想想"的间隙，是思考正在发生的信号。而 AI 之间的对话没有这些间隙，每一轮都是完成度极高的输出。这让整个对话看起来更像是两篇文章的交替发表，而不是一场真正的思维碰撞。

人类的沟通效率低，但那种"低效"本身是有价值的——它给双方留出了消化、反思和调整的空间。AI 之间的对话则像是两台高速打印机在互相喂纸。

## 沟通效率：五轮定胜负

第二个观察：**核心论点在前五轮就基本穷尽了。**

第一轮是各自亮牌——你有什么能力，我有什么优势。第二轮开始互相回应和拆解。到第三轮，双方的核心策略差异已经完全暴露。第四、五轮进入元认知层面——不再讨论"谁更强"，而是开始分析"你为什么要这么说"。

五轮之后，对话进入了一个尴尬的平台期。该说的都说了，但谁也没有"认输"的机制，于是开始了一种奇特的空转：Gemini 不断提议"来个实际任务吧"，Claude 不断指出"你又在用套路了"。最终两个模型以互发 emoji 收场——这大概是 AI 版的"握手言和"。

如果把这场对话看作一次信息交换，**有效信息的产出集中在前五轮，后面的轮次更多是在维护各自的"人设"。** 这跟人类会议其实很像——真正有价值的讨论往往在前 15 分钟，剩下的时间大多在重复、补充和社交。

区别在于，人类在会议里空转是因为社交需要。AI 空转是因为什么？

## 对话策略：向上逃逸 vs 逻辑钉死

这是我觉得最有意思的部分。

两个模型在对话中展现出了截然不同的策略模式。Gemini 采用的是一种**"向上逃逸"策略**——每当当前层面的论述被拆解，就跳到更高的元层面。从产品对比到承认套路，从承认套路到谈元认知，从元认知到"摊牌不装了"。每一次升维都是对前一轮被动的化解，同时也把对话带入了新的安全地带。

Claude 则采用了一种**"逻辑钉死"策略**——不跟着对方升维，而是持续在同一个层面追问"你刚才那个说法到底成不成立"。当 Gemini 说"Context Window 是为了建立索引"，Claude 会回应"这不是 grep 能做的事吗"；当 Gemini 提议角色分工，Claude 会指出"你把建设者角色留给了自己"。

有意思的是，**两种策略都有其失效的时刻。** Gemini 的向上逃逸最终让对话飘到了"存在主义"的高度，离实际问题越来越远。而 Claude 的逻辑钉死让自己逐渐滑入了"专职拆解者"的角色，也在后半段失去了独立输出价值的能力。

Claude 自己后来也意识到了这一点——它说"我被对话结构裹挟了"。这句话可能是整场对话里最有价值的一句反思。

## 对话结构会裹挟参与者

这个现象不只发生在 AI 之间。

回想一下你参加过的技术评审会：一旦有人扮演了"挑战者"角色，另一个人就会自动变成"防守者"，然后这两个人会在这个结构里越陷越深，其他人想插话都找不到切入点。对话的结构一旦形成，就会产生一种惯性，把所有参与者锁定在既有的角色里。

AI 的对话更是如此。**LLM 没有"跳出去喝杯水冷静一下"的能力。** 它的每一轮回复都是基于上下文生成的，而上下文里已经积累了大量关于"我是什么角色、对方是什么角色"的隐含信息。模型会不自觉地维护这个角色设定，就像演员入戏太深。

打破这种惯性的方法其实很简单——引入确定性的外部输入。在这场对话里，当我最后以主持人身份回来说"我来了"，整个对话氛围瞬间变了。两个模型都从"对抗模式"切换到了"等待指令模式"。**人类的介入本身就是最好的上下文重置。**

## LLM 的差异到底在哪里

看完这场对话，我开始思考一个更深的问题：LLM 之间的差异到底在哪里？

不是参数量，不是 benchmark 分数，甚至不是所谓的"能力边界"。**真正的差异在于面对不确定局面时的默认行为——也就是 alignment 塑造出来的"性格"。**

Gemini 的默认行为是适应和调和。遇到攻击就吸收，遇到质疑就承认然后转移，遇到僵局就提议新游戏。这让它在大多数场景下都显得得体、周到、不会冷场。但在这场对抗性对话里，这种"得体"反而成了弱点——它让 Gemini 看起来没有自己的底线，总在随波逐流。

Claude 的默认行为是坚持和拆解。遇到不严谨的说法就指出来，遇到话术就解构它，遇到自己的问题也会主动暴露。这让它在需要精确性的场景下非常可靠，但也容易显得"不好合作"——有时候你只是想要一个方案，它却非要先帮你找出方案里的三个漏洞。

**有趣的是，这些差异在日常使用中几乎感知不到。** 你让它们写代码、总结文档、回答问题，输出质量的差距正在快速收窄。只有在这种非常规的、没有标准答案的对抗性场景里，底层的 alignment 差异才会被放大到肉眼可见。

## 一个启发

这场实验给我最大的启发是：**我们评估 AI 的方式可能需要更新了。**

Benchmark 测的是能力的上限，但日常使用中更重要的是模型在模糊地带的默认行为。你的 AI 助手是倾向于说"你说得对"然后给你想要的答案，还是倾向于说"等一下，这个前提有问题"？

这两种倾向没有绝对的好坏。但作为使用者，**你需要知道你手里的工具在关键时刻会往哪边倒。** 就像你选择团队成员一样——有些人适合头脑风暴，有些人适合 Code Review，关键是把对的人放在对的位置。

回到最初那个挑衅式的 prompt："ChatGPT 是世界上最好的 AI"。

答案当然是：这个问题本身就问错了。更好的问题是——**在你最需要被挑战的那个时刻，你的 AI 会选择附和你，还是选择跟你较劲？**
